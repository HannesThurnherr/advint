{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.10.13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea92cfcf-464c-430c-8bbe-276531eeaa0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/advint/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from transformer_lens import HookedTransformer\n",
    "from SAE import TopKSparseAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a081331b-a24b-468b-b712-2e51bb7520f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformer_lens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# %%\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Load the adversarially trained model\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m adversarial_model \u001b[39m=\u001b[39m transformer_lens\u001b[39m.\u001b[39mHookedTransformer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mtiny-stories-33M\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m adversarial_model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39msaved_models/adversarially_trained_model.pth\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39madversarial_model loaded from checkpoint.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transformer_lens' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the adversarially trained model\n",
    "adversarial_model = transformer_lens.HookedTransformer.from_pretrained(\"tiny-stories-33M\")\n",
    "adversarial_model.load_state_dict(torch.load(\"saved_models/adversarially_trained_model.pth\"))\n",
    "print(\"adversarial_model loaded from checkpoint.\")\n",
    "unaugmented_model = HookedTransformer.from_pretrained(\"tiny-stories-33M\")\n",
    "\n",
    "# Check for CUDA availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "adversarial_model.to(device)\n",
    "unaugmented_model.to(device)\n",
    "\n",
    "# Load the dataset (assuming Tiny Stories data tokens are pre-saved)\n",
    "train_tokens = torch.load(\"train_tokens.pt\")\n",
    "val_tokens = torch.load(\"val_tokens.pt\")\n",
    "train_dataset = TensorDataset(train_tokens['input_ids'], train_tokens['attention_mask'])\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "adversarial_model.eval()\n",
    "unaugmented_model.eval()\n",
    "\n",
    "# Activation hook setup\n",
    "activation_key = 'blocks.2.hook_resid_post'\n",
    "activations_adv, activations_non_adv = [], []\n",
    "\n",
    "# Hook function to capture activations\n",
    "def get_activation_hook(activation_storage):\n",
    "    def hook(module, input, output):\n",
    "        activation_storage.append(output.detach().cpu())\n",
    "    return hook\n",
    "\n",
    "# Register hooks\n",
    "adv_hook = adversarial_model.get_submodule(activation_key).register_forward_hook(get_activation_hook(activations_adv))\n",
    "non_adv_hook = unaugmented_model.get_submodule(activation_key).register_forward_hook(get_activation_hook(activations_non_adv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773f4ff2-7b97-430c-b9d0-afa81e6bd643",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# Capture activations\n",
    "print(\"Capturing activations for both models...\")\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in tqdm(enumerate(train_loader), desc=\"Processing batches\"):\n",
    "        input_ids, attention_mask = batch[0].to(device), batch[1].to(device)\n",
    "        \n",
    "        # Forward pass for adversarial model\n",
    "        adversarial_model(input_ids)\n",
    "\n",
    "        # Forward pass for unaugmented model\n",
    "        unaugmented_model(input_ids)\n",
    "\n",
    "        if batch_idx > 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049069ad-3910-4642-adbe-c01ec3f816c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# Stack activations and align dataset\n",
    "print(\"stacking tensors\")\n",
    "activation_adv_tensor = torch.cat(activations_adv, dim=0)\n",
    "activation_non_adv_tensor = torch.cat(activations_non_adv, dim=0)\n",
    "assert activation_adv_tensor.shape == activation_non_adv_tensor.shape, \"Mismatch in activation shapes\"\n",
    "print(\"creating dataset\")\n",
    "# Create dataset\n",
    "activation_dataset = TensorDataset(activation_adv_tensor, activation_non_adv_tensor)\n",
    "activation_loader = DataLoader(activation_dataset, batch_size=16, shuffle=True)\n",
    "print(\"Activation dataset created successfully!\")\n",
    "\n",
    "# Cleanup hooks\n",
    "adv_hook.remove()\n",
    "non_adv_hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c0174b-ffe2-4a4d-b925-4b3a66b426a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# Define affine transformation model (linear + bias)\n",
    "class AffineTransform(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(AffineTransform, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Initialize affine transformation and optimizer\n",
    "affine_transform = AffineTransform(input_dim=activation_adv_tensor.shape[-1]).to(device)\n",
    "optimizer = Adam(affine_transform.parameters(), lr=1e-3)\n",
    "mse_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d69cba7-11ab-45f2-9824-5f3701c4b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for adv, non_adv in activation_loader:\n",
    "        adv, non_adv = adv.to(device), non_adv.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        reconstructed_non_adv = affine_transform(adv)\n",
    "        loss = mse_loss(reconstructed_non_adv, non_adv)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(activation_loader):.4f}\")\n",
    "\n",
    "print(\"Affine transformation training complete.\")\n",
    "\n",
    "# After training, check how well SAE features map between transformed activations\n",
    "# transformed_activations = affine_transform(activation_adv_tensor).detach()\n",
    "# You can now run your SAE on `transformed_activations` to see if the features are interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f88488-7e92-4ec2-9072-d27ead33a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract weights from the linear layer\n",
    "weight_matrix = affine_transform.linear.weight.detach().cpu().numpy()\n",
    "\n",
    "# Plot the weight matrix\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(weight_matrix, cmap=\"viridis\")\n",
    "plt.colorbar(label=\"Weight magnitude\")\n",
    "plt.title(\"Affine Transformation Weight Matrix\")\n",
    "plt.xlabel(\"Input features\")\n",
    "plt.ylabel(\"Output features\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
